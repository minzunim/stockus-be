import os
from dotenv import load_dotenv
import requests
from openai import OpenAI

import time
import random 

load_dotenv()


GROQ_API_KEY = os.getenv("GROQ_API_KEY")
GROQ_API_URL = "https://api.groq.com/openai/v1/chat/completions"

# ëª¨ë¸ í† í° ì œí•œ
MAX_TOKENS = 8192
CHUNK_SIZE = 2000  # ë³´ë‚¼ ë•Œ ì—¬ìœ ë¥¼ ë‘ê¸° ìœ„í•œ í¬ê¸°

def extract_keywords_llama(text: str, count: int = 5) -> list[str]:
    # prompt = f'''ë‹¤ìŒì€ í•œêµ­ì¸ë“¤ì˜ ë¯¸êµ­ ì£¼ì‹ ì»¤ë®¤ë‹ˆí‹°ì˜ ê¸€ ë‚´ìš©ë“¤ì´ì•¼. ì‚¬ëŒë“¤ì´ ë¯¸êµ­ ì£¼ì‹ í˜„í™©ì— ëŒ€í•´ì„œ ì–´ë–»ê²Œ ìƒê°í•˜ê³  ìˆëŠ”ì§€ 2~3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì¤˜:\n{text}'''

    # prompt = f'''ë‹¤ìŒì€ ì£¼ì‹ ì»¤ë®¤ë‹ˆí‹°ì— ì˜¬ë¼ì˜¨ ê¸€ë“¤ì´ì•¼.\n
    #             ê° ê¸€ì—ì„œ ì‚¬ëŒë“¤ì´ ì–´ë–¤ ì¢…ëª©ì— ê´€ì‹¬ì„ ë³´ì´ê³  ìˆëŠ”ì§€, ê·¸ë¦¬ê³  ê·¸ ê°ì •ì´ ê¸ì •/ë¶€ì •/í˜¼í•© ì¤‘ ì–´ë–¤ì§€ ìš”ì•½í•´ì„œ ì•Œë ¤ì¤˜:\n
    #             {text}\n
    #             ìš”ì•½ ê²°ê³¼ëŠ” ì•„ë˜ì²˜ëŸ¼ ì •ë¦¬í•´ì¤˜:
    #             - í…ŒìŠ¬ë¼: ê¸ì • (ìƒìŠ¹ ê¸°ëŒ€ê°)
    #             - ì—”ë¹„ë””ì•„: ë¶€ì • (ê³¼ë§¤ìˆ˜ ìš°ë ¤)'''


    # prompt = f'''Here are some posts from a stock market community.\n
    #             Please summarize which stocks people are showing interest in and what kind of sentiment they are expressing â€” positive, negative, or mixed.\n
    #             Please organize the summary in the format below:
    #             {text}\n
    #             Tesla: Positive (Expecting price increase)\n
    #             Nvidia: Negative (Concerns of being overbought)'''
    
    prompt = f'''<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a financial data analyst summarizing posts from a Korean stock community. 
                For each post, extract:
                1. The company or stock mentioned (e.g. Tesla, Nvidia, Palantir)
                2. The sentiment expressed by the user: Positive, Negative, or Mixed
                3. The reason or context in 1 short sentence

                Format your answer like this:
                - Tesla: Positive (Expecting stock price to rise after strong sales report)
                - Nvidia: Mixed (Concern about US export restrictions, but long-term growth expected)

                Here is the posts: <|eot_id|><|start_header_id|>{text}<|end_header_id|>
                
                Answer: <|eot_id|><|start_header_id|>assistant<|end_header_id|>'''

    headers = {
        "Authorization": f"Bearer {GROQ_API_KEY}",
        "Content-Type": "application/json",
    }

    data = {
        "model": "llama3-70b-8192",
        "messages": [
            {"role": "user", "content": prompt}
        ]
    }

    chunks = [text[i:i+CHUNK_SIZE] for i in range(0, len(text), CHUNK_SIZE)]
    print('chunks', len(chunks))
    results = []
    for i, chunk in enumerate(chunks):
        if i == 3:
            break
        print('chunk ê¸¸ì´ í™•ì¸', len(chunk))
        print('ëª‡ ë²ˆì§¸ chunk:', i)
        data["messages"][0]["content"] = chunk
        response = requests.post(GROQ_API_URL, headers=headers, json=data)
        response.raise_for_status()  # ìš”ì²­ ì‹¤íŒ¨ ì‹œ ì˜ˆì™¸ ë°œìƒ
        print(response.json())
        results.append(response.json()["choices"][0]["message"]["content"])
        time.sleep(random.uniform(2, 3))
    combined_text = " ".join(results)

    # response = requests.post(GROQ_API_URL, headers=headers, json=data)
    # response.raise_for_status()
    # result = response.json()

    # return result["choices"][0]["message"]["content"].strip().split("\n"

    # ìµœì¢… ìš”ì•½ ìš”ì²­
    # final_prompt = f'''ì§€ê¸ˆê¹Œì§€ ìš”ì•½í•œ í…ìŠ¤íŠ¸ë¥¼ ë§ˆì§€ë§‰ìœ¼ë¡œ í•œë²ˆ ë” ìš”ì•½í•˜ê³  í•œêµ­ì–´ë¡œ ë²ˆì—­í•´ì„œ 2~3ë¬¸ì¥ìœ¼ë¡œ ë§í•´ì¤˜:\n{combined_text}'''
    # data["messages"][0]["content"] = final_prompt

    # ìš”ì•½ ìš”ì²­
    # time.sleep(random.uniform(2, 3))

    # response = requests.post(GROQ_API_URL, headers=headers, json=data)
    # response.raise_for_status()  # ìš”ì²­ ì‹¤íŒ¨ ì‹œ ì˜ˆì™¸ ë°œìƒ
    # final_summary = response.json()["choices"][0]["message"]["content"]

    #return final_summary 
    return combined_text


def extract_keywords_gpt(text: str, count: int = 5) -> list[str]:
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

    #OpenAI.api_key = os.getenv("OPENAI_API_KEY")

    prompt = f'''
                ë‹¤ìŒ í…ìŠ¤íŠ¸ëŠ” ë¯¸êµ­ ì£¼ì‹ì— ëŒ€í•´ ì–˜ê¸°í•˜ëŠ” í•œêµ­ ì£¼ì‹ ì»¤ë®¤ë‹ˆí‹° ê²Œì‹œê¸€ë“¤ì„ ëª¨ì€ ê±°ì•¼
                ì´ ëŒ€í™” ë‚´ìš©ì„ ë³´ê³  ì‚¬ëŒë“¤ì´ í˜„ì¬ ì–´ë–¤ ì£¼ì‹ì— ê´€ì‹¬ì„ ê°–ê³  ê·¸ ì£¼ì‹ë“¤ì— ì–´ë–¤ ê°ì •ì„ ê°–ê³  ìˆëŠ”ì§€ í‘œí˜„í•´ì¤˜ (ê¸ì •, ë¶€ì •, ì¤‘ë¦½)
                í˜•ì‹ì€ ë‹¤ìŒê³¼ ê°™ì´ ì¶œë ¥í•´ì¤˜.

                ğŸ“Œ [ì£¼ì‹ ì¢…ëª©ëª…] (ê°ì •): í•œ ì¤„ ìš”ì•½1. í•œ ì¤„ ìš”ì•½2.
                ğŸ“Œ [ì£¼ì‹ ì¢…ëª©ëª…] (ê°ì •): í•œ ì¤„ ìš”ì•½1. í•œ ì¤„ ìš”ì•½2.
                âœ¨ ì „ë°˜ì ì¸ ë¶„ìœ„ê¸° ìš”ì•½ (2-3ë¬¸ì¥ ì •ë„ë¡œ ê°„ê²°í•˜ê²Œ, ì¹œê·¼í•œ ë§íˆ¬ë¡œ)
            '''

    print(len(text))

    response = client.chat.completions.create(
        model="gpt-4.1-nano",
        messages=[
            {"role": "system", "content": prompt},
            {"role": "user", "content": text}
        ]
    )

    # print(response.output_text)
    return response.choices[0].message.content